{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ed062b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tomo_encoders.neural_nets.surface_segmenter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_466/3334984830.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#from tomo_encoders.mesh_processing.vox2mesh import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtomo_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_nets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface_segmenter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSurfaceSegmenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtomo_encoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtomo_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_voids\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_voids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tomo_encoders.neural_nets.surface_segmenter'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tomo_encoders import DataFile\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/data02/MyArchive/aisteer_3Dencoders/TomoEncoders/scratchpad/voids_paper/configs/')\n",
    "from params import model_path, get_model_params\n",
    "import tensorflow as tf\n",
    "\n",
    "#from tomo_encoders.mesh_processing.vox2mesh import *\n",
    "from tomo_encoders.neural_nets.surface_segmenter import SurfaceSegmenter\n",
    "from tomo_encoders import Grid, Patches\n",
    "from tomo_encoders.labeling.detect_voids import export_voids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52af790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ####################################################### \n",
      "\n",
      "\n",
      "Model is M_a02\n",
      "n_filters [16, 32]\n",
      "n_blocks 2\n",
      "activation lrelu\n",
      "batch_norm True\n",
      "isconcat [True, True]\n",
      "pool_size [2, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 12:00:41.524875: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-29 12:00:41.575426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-29 12:00:41.575483: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-29 12:00:41.575540: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-29 12:00:41.575559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-29 12:00:41.575580: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-29 12:00:41.575599: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-29 12:00:41.575631: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-03-29 12:00:41.575649: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-29 12:00:41.575876: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-29 12:00:41.578556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "######## START GPU SETTINGS ############\n",
    "########## SET MEMORY GROWTH to True ############\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass        \n",
    "######### END GPU SETTINGS ############\n",
    "\n",
    "# FILE I/O\n",
    "dir_path = '/data02/MyArchive/tomo_datasets/AM_part_Xuan/data/xzhang_feb22_rec/wheel1_sam1'\n",
    "save_path = '/data02/MyArchive/tomo_datasets/AM_part_Xuan/seg_data/xzhang_feb22_rec/wheel1_sam1'\n",
    "if not os.path.exists(save_path): os.makedirs(save_path)\n",
    "\n",
    "\n",
    "# STITCHING PARAMETERS\n",
    "id_start = [0,75,75]\n",
    "id_end = [849,849,924]\n",
    "\n",
    "\n",
    "# SEGMENTATION PARAMETERS\n",
    "model_tag = \"M_a02\"\n",
    "model_names = {\"segmenter\" : \"segmenter_Unet_%s\"%model_tag}\n",
    "model_params = get_model_params(model_tag)\n",
    "# patch size\n",
    "wd = 32\n",
    "\n",
    "# VOID DETECTION PARAMETERS\n",
    "N_MAX_DETECT = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dae287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stitched(dir_path, id_start, id_end):\n",
    "    n_layers = len(id_start)\n",
    "    Vx_full = []\n",
    "    for il in range(n_layers):\n",
    "        ds = DataFile(os.path.join(dir_path, f'layer{il+1}'), tiff=True)        \n",
    "        Vx_full.append(ds.read_chunk(axis=0, slice_start=id_start[il], slice_end=id_end[il], return_slice=False).astype(np.float32))\n",
    "    Vx_full = np.concatenate(Vx_full, axis=0)\n",
    "\n",
    "    print(Vx_full.shape)\n",
    "    return Vx_full\n",
    "\n",
    "\n",
    "def segment_volume(Vx_full, fe, wd):\n",
    "\n",
    "    p_grid = Grid(Vx_full.shape, width = wd)\n",
    "    min_max = Vx_full[::4,::4,::4].min(), Vx_full[::4,::4,::4].max()\n",
    "    x = p_grid.extract(Vx_full)\n",
    "    x = fe.predict_patches(\"segmenter\", x[...,np.newaxis], 256, None, min_max = min_max)[...,0]\n",
    "    print(f\"shape of x array is {x.shape}\")\n",
    "    p_grid.fill_patches_in_volume(x, Vx_full) # values in Vx_full are converted to binary (0 and 1) in-place\n",
    "    Vx_full = Vx_full.astype(np.uint8)\n",
    "    return Vx_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44a2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "Found existing tiff folder: layer1\n",
      "Dataset shape: (924, 880, 1370)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_chunk() got an unexpected keyword argument 'return_slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31192/639968768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# make a big volume that stitches together all layers in one volume; Vx_full.shape will be (tot_ht, ny, nx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mVx_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_stitched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31192/3189561808.py\u001b[0m in \u001b[0;36mmake_stitched\u001b[0;34m(dir_path, id_start, id_end)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mil\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'layer{il+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mVx_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_start\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mil\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_end\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mil\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_slice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mVx_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVx_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_chunk() got an unexpected keyword argument 'return_slice'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "\n",
    "    # do stuff\n",
    "    # STEP 1\n",
    "    # make a big volume that stitches together all layers in one volume; Vx_full.shape will be (tot_ht, ny, nx)\n",
    "    t_start = time.time()\n",
    "    Vx_full = make_stitched(dir_path, id_start, id_end)\n",
    "    \n",
    "\n",
    "    # make sure Vx_full shape is divisible by 32\n",
    "    nz, ny, nx = Vx_full.shape\n",
    "    print(f\"shape of Vx_full was {Vx_full.shape}\")\n",
    "    Vx_full = Vx_full[:-(nz%wd), :-(ny%wd), :-(nx%wd)].copy()\n",
    "    print(f\"after cropping, shape of Vx_full is {Vx_full.shape}\")\n",
    "    \n",
    "    print(f\"TIME stitching: {time.time()-t_start:.2f} seconds\")\n",
    "\n",
    "\n",
    "    ds_save = DataFile(os.path.join(save_path, \"stitched\"), tiff = True, d_shape = Vx_full.shape, d_type = Vx_full.dtype)\n",
    "    ds_save.create_new(overwrite=True)\n",
    "    ds_save.write_full(Vx_full)\n",
    "\n",
    "    # STEP 2\n",
    "    # Process Vx_full into Vy_full where Vy_full contains only ones (inside void) and zeros (inside metal)\n",
    "    # initialize segmenter fCNN\n",
    "    fe = SurfaceSegmenter(model_initialization = 'load-model', \\\n",
    "                         model_names = model_names, \\\n",
    "                         model_path = model_path)    \n",
    "    fe.test_speeds(128,n_reps = 5, input_size = (wd,wd,wd))    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    Vx_full = segment_volume(Vx_full, fe, wd)\n",
    "    print(f\"TIME segmentation: {time.time()-t_start:.2f} seconds\")\n",
    "\n",
    "    ds_save = DataFile(os.path.join(save_path, \"segmented\"), tiff = True, d_shape = Vx_full.shape, d_type = Vx_full.dtype)\n",
    "    ds_save.create_new(overwrite=True)\n",
    "    ds_save.write_full(Vx_full)\n",
    "\n",
    "\n",
    "    # STEP 3\n",
    "    # Process Vy_full into void_vols where void_vols is a list of many ndarrays with different shapes (pz, py, px) representing each void\n",
    "    # Also output cz, cy, cx for each void_vol in void_vols giving the center of the void volume w.r.t. the coordinates in Vy_full\n",
    "    x_voids, p_voids = export_voids(Vx_full, N_MAX_DETECT, TIMEIT = True, invert = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # STEP 4\n",
    "    # Process all void_vols into void_surfs in the form of a single .ply file and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c04a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
